{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_MachineLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n25CFY4y9RBk",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/BITalinoWorld/python-lab-guides/raw/master/BITalino%20Hands-on/images/bitalinobar.jpg)\n",
        "# Swimming Classification Using BioSPPy\n",
        "\n",
        "On this example we will perform the classification of swimming styles using the biosppy library and machine learning tools.\n",
        "To perform this example every cell must be executed. To do so click run ([ ]) in the top left of every cell.\n",
        "A warning will appear to reset all runtimes before running, click to accept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K0fJhc-9MBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Import libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Clone the repo.\n",
        "!pip install biosppy >/dev/null 2>&1\n",
        "import biosppy as bs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNNfMJHW-QEN",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/BITalinoWorld/python-lab-guides/raw/master/BITalino%20Hands-on/images/bitalinobar.jpg)\n",
        "\n",
        "# 1. Load Dataset\n",
        "\n",
        "In this example you will use swimming files shared through a google drive link. \n",
        "Our example file contains movement data from swimmers. \n",
        "To acess the data, you will have to load it from Google Drive. For that, install PyDrive and follow the instructions that will appear:\n",
        "- choose the google account you want to use\n",
        "- allow for Google Cloud SDK to access your google account\n",
        "- copy the verification code and place it on the box below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDMCiwY7_s-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Load data from Google Drive\n",
        "!pip install -U -q PyDrive >/dev/null 2>&1\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQhSOP7OIazL",
        "colab_type": "text"
      },
      "source": [
        "This application allows to get data from Google Drive. For that, we just need the link related to the data file. The important part of the shareable link is the \"id\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxCmiEXOABrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link = 'https://drive.google.com/file/d/1_Frt5Kf9xm4HO78ccRe9DBdrO39FjUwZ/view?usp=sharing' # The shareable link\n",
        "id = link.split('/')[-2] # --> id is \"1_Frt5Kf9xm4HO78ccRe9DBdrO39FjUwZ\"\n",
        "#download the file\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "data_name = 'swim_pitch_segmented'\n",
        "downloaded.GetContentFile(data_name)  \n",
        "#open the file\n",
        "data = pickle.load(open(data_name,'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImB7LuOxG17n",
        "colab_type": "text"
      },
      "source": [
        "**If the import was sucessfull, after refreshing, the file 'swim_pitch_segmented' will appear on the Files tab on your left side of the screen.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmHKNTn6KGj3",
        "colab_type": "text"
      },
      "source": [
        "#1.1. Check data\n",
        "\n",
        "The data file contains each pool run already segmented. The movement information is given by Yaw, Pitch, Roll, Accelerometer (x,y,z), Gyroscope (x,y,z) and Magnetometer (x,y,z).\n",
        "\n",
        "At first glance, it is difficult to know which modalities are more relevant for movement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Fy4LFMBPyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame.from_dict(data[0])[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPSv9kKMK7yp",
        "colab_type": "text"
      },
      "source": [
        "#1.2. Plot data\n",
        "\n",
        "To have some insight on the relevant modalities for swimming motion, we can plot one modality at a time for a specific user. Using the data file.\n",
        "\n",
        "You can change **user** and **sensor** variables to see diferent modalities and different swimmers.\n",
        "\n",
        "This plot was saved locally as \"Swim_styles.png\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSYM2lfjCTAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose parameters\n",
        "user = 1\n",
        "sensor = 'Pitch'\n",
        "\n",
        "#create figure\n",
        "plt.figure(figsize=(25,5))\n",
        "#join the user segments\n",
        "plt.title('Swimmer ' + str(user))\n",
        "join_time = np.concatenate(data[user]['Time'])\n",
        "join_data = np.concatenate(data[user][sensor])\n",
        "#plot joint data\n",
        "plt.plot(join_time, join_data)\n",
        "for lab in range(len(data[user]['Label'])):\n",
        "    middle = len(data[user]['Time'][lab])//2\n",
        "    plt.text(data[user]['Time'][lab][0]+middle, np.max(np.concatenate(data[user][sensor])), data[user]['Label'][lab], fontsize=12)\n",
        "plt.savefig('Swim_styles.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5DSgAhLcFutW"
      },
      "source": [
        "![alt text](https://github.com/BITalinoWorld/python-lab-guides/raw/master/BITalino%20Hands-on/images/bitalinobar.jpg)\n",
        "\n",
        "# 2. Machine Learning\n",
        "\n",
        "## Key ML Terminology\n",
        "\n",
        "![alt text](https://i.ibb.co/xs6rJ5d/swim-ML.png)\n",
        "\n",
        "Given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis [1](http://cs229.stanford.edu/notes2019fall/cs229-notes1.pdf).\n",
        "\n",
        "\n",
        "A **feature** is an input variable [2](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology).\n",
        "\n",
        "A **label** is the thing we're predicting—the signal modality [2](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw5hwxYlI33_",
        "colab_type": "text"
      },
      "source": [
        "# 2.2. Feature Extraction\n",
        "![alt text](https://i.ibb.co/StPzn0v/Captura-de-ecr-2019-09-26-s-16-12-11.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gH7SPa4vOkn",
        "colab_type": "text"
      },
      "source": [
        "Feature Calculation through biosppy \n",
        "```\n",
        "data = pickle.load(open('swim_pitch_segmented','rb'))\n",
        "def swim_features_calculation(data, sensor_list=['Pitch', 'Roll', 'Yaw', 'Az', 'Ay', 'Ax'])\n",
        "\n",
        "    user_feat, user_label = [], []\n",
        "    for user in range(len(data)):\n",
        "        user_df = pd.DataFrame.from_dict(data[user])\n",
        "        for cl in sensor_list:\n",
        "            label_ = []\n",
        "            for line in range(len(user_df[cl])):\n",
        "                feat_row= bs.signals.tools.signal_stats(user_df[cl][line])\n",
        "                feat_names = [cl + '_' + feat for feat in feat_row._names]\n",
        "                feat_row = pd.DataFrame([feat_row._values], columns=feat_names)\n",
        "                feat_rows = feat_row if line == 0 else pd.concat([feat_rows, feat_row], axis=0, sort=False, ignore_index=True)\n",
        "\n",
        "            label_ = user_df['Label'].values\n",
        "            feats = feat_rows.copy() if cl == sensor_list[0] else pd.concat([feats, feat_rows], axis=1, sort=False)\n",
        "\n",
        "        user_feat += [pd.DataFrame(standarize(feats), columns=feats.columns)]\n",
        "        user_label += [label_]\n",
        "\n",
        "    pickle.dump(user_feat, open('swim_pitch_feats_pool','wb'))\n",
        "    pickle.dump(user_label, open('swim_pitch_labels_pool', 'wb'))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmM9uMv3Nb1a",
        "colab_type": "text"
      },
      "source": [
        "Feature Calculation is a process that may take some time. To perform it in the swimming data we created the function \"swim_features_calculation\" that uses biosppy's signal_stats function to calculate simple measures such as average mean, standard deviation, maximum value, and others. This function allows to choose specific modalities and it creates a feature vector **user_feat** and a labels_vector **user_label** which were saved into separate files.\n",
        "\n",
        "In order to save time we will download this files which are available on the shareable links below, using the same method as for the previous case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uviM269KX-me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download features file\n",
        "\n",
        "link_feats = 'https://drive.google.com/file/d/17stX00p_3z6b7q-Z9hc0tjvTZJZjQIzz/view?usp=sharing' # The shareable link\n",
        "id = link_feats.split('/')[-2]\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('swim_pitch_feats_pool')  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz4Nm6UckWPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download labels file\n",
        "\n",
        "link_labels = 'https://drive.google.com/file/d/1ysJw3Y7vgOQeQT_5vfoUZdX0Meqe7T-F/view?usp=sharing' # The shareable link\n",
        "id = link_labels.split('/')[-2]\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('swim_pitch_labels_pool')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCML38bWEPos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will load feature vector as X and labels vector as Y\n",
        "\n",
        "X = pickle.load(open('swim_pitch_feats_pool','rb'))\n",
        "Y = pickle.load(open('swim_pitch_labels_pool','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjrpSGSkW47U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check all features for one specific user. For each swimming lap (0 to 15) all features were calculated for the designated modalities (Pitch, Roll, Yaw, Az, Ay, Ax).\n",
        "user = 10\n",
        "X[user]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CSTHrYJKcj1",
        "colab_type": "text"
      },
      "source": [
        "# 1.2.3. Splitting Data\n",
        "\n",
        "![alt text](https://i.ibb.co/vY7zFjM/swim-Split-Data.png)\n",
        "\n",
        "*   training set—a subset to train a model.\n",
        "\n",
        "*   test set—an independent subset to test the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZp4MIeCdywH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change data type to array\n",
        "X_array = []\n",
        "Y_array = []\n",
        "for user in range(len(X)):\n",
        "    X_array.append(X[user].values)\n",
        "    Y_array.append(np.array(Y[user]))\n",
        "X_array = np.array(X_array)\n",
        "Y_array = np.array(Y_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lpuPZQxHlo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate in train and set set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.concatenate(X_array), np.concatenate(Y_array), test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9Awxh77iZ-c",
        "colab_type": "text"
      },
      "source": [
        "# 2.4. Learn Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exj2WPFJ1fjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose classifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "names = [ \"Decision Tree\", \"GaussianNB\",\"Gaussian Process\", \"GradientBoosting\",\n",
        "          \"Bernoulli NB\",\"Logistic Regression\"]\n",
        "\n",
        "classifiers = [\n",
        "        DecisionTreeClassifier(),\n",
        "        GaussianNB(),\n",
        "        GaussianProcessClassifier(),\n",
        "        GradientBoostingClassifier(),\n",
        "        BernoulliNB(),\n",
        "        LogisticRegression()\n",
        "]\n",
        "\n",
        "classifier = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfKSCAYxa0f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit supervised Learning Classifiers on the training set data\n",
        "\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spWkklKqQ7z-",
        "colab_type": "text"
      },
      "source": [
        "# 2.5. Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O60yrhuo3S_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted = classifier.predict(X_test)\n",
        "y_predicted\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P5Tsk2T_rxG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title def plot_confusion_matrix(y_true, y_pred, true_labels=None, normalize=False)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, true_labels=None, normalize=False, title=''):\n",
        "    \"\"\"\n",
        "\n",
        "    :param y_true: type(array), contains true labels\n",
        "    :param y_pred: type(array), contains predicted labels\n",
        "    :param true_labels: list of unique labels\n",
        "    :param normalize: boolean\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if true_labels is None:\n",
        "        true_labels = np.unique(y_true)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=true_labels)\n",
        "    if normalize:\n",
        "        cm = np.round(cm / np.max(cm), 2)\n",
        "        \n",
        "    plt.figure(figsize=(10,5))\n",
        "    ax = plt.subplot(1,1,1)\n",
        "    ax.set_title(title)\n",
        "    sb.heatmap(cm, annot=True, ax=ax, fmt='g', cmap='Blues')  # annot=True to annotate cells\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted', fontsize=20)\n",
        "    ax.xaxis.set_label_position('top')\n",
        "    ax.xaxis.set_ticklabels(true_labels, fontsize=10)\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_ylabel('True', fontsize=20)\n",
        "    ax.yaxis.set_ticklabels(true_labels, fontsize=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NftO76MoeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evalutaion on the test set\n",
        "classifier.fit(X_train, y_train)\n",
        "y_predicted = classifier.predict(X_test)\n",
        "target_names = np.unique(y_test)\n",
        "plot_confusion_matrix(y_test, y_predicted, target_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-WD-LligGe",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/BITalinoWorld/python-lab-guides/raw/master/BITalino%20Hands-on/images/bitalinobar.jpg)\n",
        "\n",
        "# 3. Feature Selection\n",
        "A very high dimensional feature vector can introduce overfitting and high computational cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "lonL_PFc6Qmv",
        "colab": {}
      },
      "source": [
        "#@title def cross_validation(X_train, y_train, features_descrition, classifier, random_num)\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "def cross_validation(classifier, X_train, y_train, feat_idx=None, random_num=0.42, test_size=0.25):\n",
        "\n",
        "    list_idx = np.arange(len(X_train))\n",
        "\n",
        "    kf = KFold(n_splits=int(1//test_size), random_state=random_num, shuffle=False)\n",
        "    acc, y_pred, y_true, x_test = [], [], [], []\n",
        "\n",
        "    for train_index, test_index in kf.split(X_train):\n",
        "\n",
        "        Ux_train = np.concatenate(X_train[train_index])\n",
        "        Ux_test = np.concatenate(X_train[test_index])\n",
        "        Uy_train, Uy_test = np.concatenate(y_train[train_index]), np.concatenate(y_train[test_index])\n",
        "        if feat_idx is not None:\n",
        "            Ux_train, Ux_test = Ux_train[:, feat_idx], Ux_test[:,feat_idx]\n",
        "\n",
        "            if type(feat_idx) == int:\n",
        "                Ux_train = Ux_train.reshape(-1,1)\n",
        "                Ux_test = Ux_test.reshape(-1, 1)\n",
        "\n",
        "        classifier.fit(Ux_train, Uy_train)\n",
        "        U_pred = classifier.predict(Ux_test)\n",
        "        acc_ = np.round(accuracy_score(Uy_test, U_pred)*100,2)\n",
        "        acc.append(acc_)\n",
        "    return acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6IBEmm15akJ",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title def FSE_cross_validation(X_train, y_train, features_descrition, classifier, random_num)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def FSE_cross_validation(X_train, y_train, features_descrition, classifier, random_num):\n",
        "    \"\"\" Performs a sequential forward feature selection.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_train : array\n",
        "        Training set feature-vector.\n",
        "\n",
        "    y_train : array\n",
        "        Training set class-labels groundtruth.\n",
        "\n",
        "    features_descrition : array\n",
        "        Features labels.\n",
        "\n",
        "    classifier : object\n",
        "        Classifier.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    FS_idx : array\n",
        "        Selected set of best features indexes.\n",
        "\n",
        "    FS_lab : array\n",
        "        Label of the selected best set of features.\n",
        "\n",
        "    FS_X_train : array\n",
        "        Transformed feature-vector with the best feature set.\n",
        "    \"\"\"\n",
        "    total_acc, total_std, FS_lab, acc_list, acc_std, FS_idx = [], [], [], [], [], []\n",
        "    X_train = np.array(X_train)\n",
        "\n",
        "    print(\"*** Feature selection started ***\")\n",
        "    for feat_idx, feat_name in enumerate(features_descrition):\n",
        "\n",
        "        cv_result = cross_validation(classifier, X_train, y_train, feat_idx, random_num)\n",
        "        acc_list.append((np.array(cv_result).prod()**(1.0/len(cv_result))))\n",
        "        acc_std.append(np.std(cv_result))\n",
        "\n",
        "    curr_acc_idx = np.argmax(acc_list)\n",
        "    FS_lab.append(features_descrition[curr_acc_idx])\n",
        "    last_acc = acc_list[curr_acc_idx]\n",
        "    total_acc.append(last_acc)\n",
        "    total_std.append(acc_std[curr_acc_idx])\n",
        "    FS_idx.append(curr_acc_idx)\n",
        "    while 1:\n",
        "        acc_list = []\n",
        "        print(FS_lab)\n",
        "        for feat_idx, feat_name in enumerate(features_descrition):\n",
        "            if feat_name not in FS_lab:\n",
        "                feats_idx = FS_idx[:]\n",
        "                feats_idx.append(feat_idx)\n",
        "                cv_result = cross_validation(classifier, X_train, y_train, feats_idx, random_num)\n",
        "                acc_list.append(np.array(cv_result).prod()**(1.0/len(cv_result)))\n",
        "                acc_std.append(np.std(cv_result))\n",
        "\n",
        "            else:\n",
        "                acc_list.append(0)\n",
        "        curr_acc_idx = np.argmax(acc_list)\n",
        "        if last_acc < acc_list[curr_acc_idx]:\n",
        "            FS_lab.append(features_descrition[curr_acc_idx])\n",
        "            last_acc = acc_list[curr_acc_idx]\n",
        "            total_acc.append(last_acc)\n",
        "            total_std.append(acc_std[curr_acc_idx])\n",
        "            FS_idx.append(curr_acc_idx)\n",
        "        else:\n",
        "            print(\"FINAL Features: \" + str(FS_lab))\n",
        "            print(\"Number of selected features\", len(FS_lab))\n",
        "            print(\"Features idx: \", FS_idx)\n",
        "            print(\"Acc: \", str(total_acc))\n",
        "            print(curr_acc_idx)\n",
        "            print('Acc std ', str(total_std))\n",
        "            print(\"From \", str(X_train[0].shape[1]), \" features to \", str(len(FS_lab)))\n",
        "            break\n",
        "    print(\"*** Feature selection finished ***\")\n",
        "    FS_X_train = []\n",
        "\n",
        "\n",
        "    return np.array(FS_idx), np.array(FS_lab), np.array([total_acc[-1], total_std[-1]]), FS_X_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLf8RYznHpU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature selection\n",
        "feats_names = X[0].columns\n",
        "idx_feat, best_feats, acc, _ = FSE_cross_validation(X_array, Y_array, feats_names, classifier, random_num=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5oEmxatHrVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Update classifier for best features set\n",
        "remove_columns = [feats_names[idx] for idx in range(len(feats_names)) if feats_names[idx] not in best_feats]\n",
        "X_bf_array = []\n",
        "Y_bf_array = []\n",
        "for user in range(len(X)):\n",
        "    X_bf_array.append(X[user].drop(columns=remove_columns).values)\n",
        "    Y_bf_array.append(np.array(Y[user]))\n",
        "X_bf_array = np.array(X_bf_array)\n",
        "Y_bf_array = np.array(Y_bf_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol8g4vntk8_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.concatenate(X_bf_array), np.concatenate(Y_bf_array), test_size=0.33, random_state=42)\n",
        "#train classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "#inference\n",
        "y_predicted = classifier.predict(X_test)\n",
        "target_names = np.unique(y_test)\n",
        "#plot result in a confusion matrix\n",
        "plot_confusion_matrix(y_test, y_predicted, target_names)\n",
        "print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcmzWiRqjiAN",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/BITalinoWorld/python-lab-guides/raw/master/BITalino%20Hands-on/images/bitalinobar.jpg)"
      ]
    }
  ]
}